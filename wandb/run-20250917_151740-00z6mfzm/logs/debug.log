2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_setup.py:_flush():68] Current SDK version is 0.19.4
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_setup.py:_flush():68] Configure stats pid to 1143470
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_setup.py:_flush():68] Loading settings from /home/mhuber/.config/wandb/settings
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_setup.py:_flush():68] Loading settings from /home/mhuber/Thesis/GitHub/practicalwork/wandb/settings
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_init.py:setup_run_log_directory():624] Logging user logs to /home/mhuber/Thesis/GitHub/practicalwork/wandb/run-20250917_151740-00z6mfzm/logs/debug.log
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_init.py:setup_run_log_directory():625] Logging internal logs to /home/mhuber/Thesis/GitHub/practicalwork/wandb/run-20250917_151740-00z6mfzm/logs/debug-internal.log
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_init.py:init():743] calling init triggers
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_init.py:init():748] wandb.init called with sweep_config: {}
config: {'main': {'image_dir': '/home/mhuber/Thesis/data/KermanyV3_micro/train', 'latents_path': './latents/lima', 'trained_autoencoder_path': './runs/lima_20250917_1334/model_best.pt', 'trained_unet_path': None}, 'env_config': {'data_base_dir': './data', 'embedding_base_dir': './embeddings', 'json_data_list': './temp_work_dir/datalist.json', 'log_dir': './logs', 'model_dir': './models', 'model_filename': 'diff_unet_ckpt.pt', 'output_dir': './predictions', 'output_prefix': 'unet_2d', 'trained_unet_path': None, 'trained_autoencoder_path': './runs/lima_20250917_1334/model_best.pt'}, 'model': {'autoencoder': {'spatial_dims': 2, 'in_channels': 1, 'out_channels': 1, 'latent_channels': 4, 'num_channels': [64, 128, 256], 'num_res_blocks': [2, 2, 2], 'norm_num_groups': 32, 'norm_eps': 1e-06, 'attention_levels': [False, False, False], 'with_encoder_nonlocal_attn': False, 'with_decoder_nonlocal_attn': False, 'use_checkpointing': False, 'use_convtranspose': False, 'norm_float16': True, 'num_splits': 1, 'dim_split': 1}}, 'model_config': {'save_every': 1, 'diffusion_unet_train': {'batch_size': 8, 'cache_rate': 0, 'lr': 0.0001, 'n_epochs': 1000}, 'diffusion_unet_inference': {'dim': [256, 256, 128], 'spacing': [1.0, 1.0, 1.0], 'top_region_index': [0, 1, 0, 0], 'bottom_region_index': [0, 0, 1, 0], 'random_seed': 42, 'num_inference_steps': 1000}}, 'vae_def': {'spatial_dims': 2, 'image_channels': 1, 'latent_channels': 4, 'autoencoder_def': {'_target_': 'monai.apps.generation.maisi.networks.autoencoderkl_maisi.AutoencoderKlMaisi', 'spatial_dims': '@spatial_dims', 'in_channels': '@image_channels', 'out_channels': '@image_channels', 'latent_channels': '@latent_channels', 'num_channels': [64, 128, 256], 'num_res_blocks': [2, 2, 2], 'norm_num_groups': 32, 'norm_eps': 1e-06, 'attention_levels': [False, False, False], 'with_encoder_nonlocal_attn': False, 'with_decoder_nonlocal_attn': False, 'use_checkpointing': False, 'use_convtranspose': False, 'norm_float16': True, 'num_splits': 8, 'dim_split': 1}, 'diffusion_unet_def': {'_target_': 'monai.apps.generation.maisi.networks.diffusion_model_unet_maisi.DiffusionModelUNetMaisi', 'spatial_dims': '@spatial_dims', 'in_channels': '@latent_channels', 'out_channels': '@latent_channels', 'num_channels': [64, 128, 256, 512], 'attention_levels': [False, False, True, True], 'num_head_channels': [0, 0, 32, 32], 'num_res_blocks': 2, 'use_flash_attention': True, 'include_top_region_index_input': False, 'include_bottom_region_index_input': False, 'include_spacing_input': False}, 'controlnet_def': {'_target_': 'monai.apps.generation.maisi.networks.controlnet_maisi.ControlNetMaisi', 'spatial_dims': '@spatial_dims', 'in_channels': '@latent_channels', 'num_channels': [64, 128, 256, 512], 'attention_levels': [False, False, True, True], 'num_head_channels': [0, 0, 32, 32], 'num_res_blocks': 2, 'use_flash_attention': True, 'conditioning_embedding_in_channels': 8, 'conditioning_embedding_num_channels': [8, 32, 64]}, 'noise_scheduler': {'_target_': 'monai.networks.schedulers.ddpm.DDPMScheduler', 'num_train_timesteps': 1000, 'beta_start': 0.0015, 'beta_end': 0.0195, 'schedule': 'scaled_linear_beta', 'clip_sample': False}}}
2025-09-17 15:17:40,934 INFO    MainThread:1143470 [wandb_init.py:init():776] starting backend
2025-09-17 15:17:41,140 INFO    MainThread:1143470 [wandb_init.py:init():780] sending inform_init request
2025-09-17 15:17:41,144 INFO    MainThread:1143470 [backend.py:_multiprocessing_setup():97] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-09-17 15:17:41,144 INFO    MainThread:1143470 [wandb_init.py:init():795] backend started and connected
2025-09-17 15:17:41,147 INFO    MainThread:1143470 [wandb_init.py:init():888] updated telemetry
2025-09-17 15:17:41,147 INFO    MainThread:1143470 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-09-17 15:17:41,725 INFO    MainThread:1143470 [wandb_init.py:init():967] starting run threads in backend
2025-09-17 15:17:41,822 INFO    MainThread:1143470 [wandb_run.py:_console_start():2409] atexit reg
2025-09-17 15:17:41,822 INFO    MainThread:1143470 [wandb_run.py:_redirect():2259] redirect: wrap_raw
2025-09-17 15:17:41,822 INFO    MainThread:1143470 [wandb_run.py:_redirect():2324] Wrapping output streams.
2025-09-17 15:17:41,822 INFO    MainThread:1143470 [wandb_run.py:_redirect():2349] Redirects installed.
2025-09-17 15:17:41,824 INFO    MainThread:1143470 [wandb_init.py:init():1009] run started, returning control to user process
2025-09-17 15:17:42,562 INFO    MainThread:1143470 [wandb_run.py:_config_callback():1270] config_cb None None {'batch_size': 8, 'learning_rate': 0.0001, 'num_epochs': 1000, 'num_timesteps': 1000, 'start_epoch': 0}
2025-09-17 16:27:20,938 WARNING MsgRouterThr:1143470 [router.py:message_loop():75] message_loop has been closed
